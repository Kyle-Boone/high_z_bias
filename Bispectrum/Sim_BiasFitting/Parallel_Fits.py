'''
This is the plan

⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣠⠤⠒⠋⢉⣉⣉⣉⠉⠙⠒⠒⠤⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣤⣀⠔⠋⠀⠀⠰⢟⠟⠛⠻⠟⠛⠀⢠⣿⡿⠿⣷⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢰⡿⢿⠆⠀⠀⠀⠀⠀⠉⢭⣿⣿⢇⠄⠀⠈⠻⣗⣶⣾⠙⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⡁⠸⠀⠀⠀⠀⠀⠀⠀⠀⠉⠀⠀⢀⣤⣄⣀⠘⡏⠋⠁⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢠⣞⣿⡷⣶⡀⠀⠀⠀⠀⠀⠀⢄⡀⠀⠀⠀⠀⠀⠈⠑⢚⡀⠀⡆⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣴⣿⢛⣥⡾⠛⢙⣄⠀⠀⠀⠀⠀⠀⠈⠉⠒⠒⠒⠖⠒⠚⠛⠁⢸⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣠⣼⣿⣿⣿⣏⣀⣴⣿⣿⣷⢦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡴⣿⣧⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⢀⣠⣴⣾⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⠃⢰⣿⣷⡦⢤⣄⡀⢀⣀⣀⡀⢤⣴⠻⣿⣦⣙⣷⣦⣀⠀⠀⠀⠀⠀⠀⠀
⠀⠀⢀⣤⣾⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⠛⠿⠶⢿⣿⣿⠧⣸⣿⣇⣀⣿⣿⣧⣈⣿⣇⣸⣿⣿⣿⣿⣿⣿⣶⣄⡀⠀⠀⠀
⠀⣰⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣷⣶⣦⣤⣬⣿⣇⣸⣿⣯⣉⣿⣿⣿⣉⣿⣷⠾⠿⠿⣿⣿⣿⣿⣿⣿⣿⣦⡀⠀
⠀⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣯⠉⠉⠉⠉⣿⣿⣿⣿⣿⣿⢻⣹⣿⣿⣿⣿⣶⣶⣶⣾⣿⣿⣿⣿⣿⣿⣿⣿⠀
⢀⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣶⣶⣶⣶⣿⣿⣿⣿⣿⣿⠘⣿⣿⣿⣿⣿⡟⠛⠛⢻⣿⣿⣿⣿⣿⣿⣿⣿⡇
⢸⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡟⠛⠛⠛⢻⣿⣿⣿⣿⣿⣶⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡇
⢸⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣇⣀⣀⣀⣸⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣇⣀⣀⣸⣿⣿⣿⣿⣿⣿⣿⣿⡇
⢸⣿⣿⣿⣿⣿⣿⣿⢻⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡇
⠈⣿⣿⣿⣿⣿⣿⣿⠀⠹⣿⣿⣿⣿⣿⣿⣿⣿⣿⠁⠀⠀⠀⢸⣿⣿⣿⣿⣿⣻⣿⣿⣿⣿⣿⣹⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⠁
⠀⣿⣿⣿⣿⣿⣿⣿⠀⠀⠹⣿⣿⣿⣿⣿⣿⣿⣿⣶⣶⣶⣶⣾⣿⣿⣿⣿⡿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⠃⣿⣿⣿⣿⣿⣿⡟⠀
⠀⢹⣿⣿⣿⣿⣿⣿⡀⠀⠀⢻⣿⣿⣿⣿⣿⣿⡿⠛⠛⠛⠛⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣧⣿⣿⣿⠃⢸⣿⣿⣿⣿⣿⣿⠀⠀
⠀⠈⣿⣿⣿⣿⣿⣿⣇⠀⠀⢸⣿⣿⣿⣿⣿⣿⣧⣀⣀⣀⣠⣿⣿⣿⣿⣿⡿⣿⣿⣿⣿⣿⣿⣿⣿⡇⠀⢸⣿⣿⣿⣿⣿⣿⠀⠀
⠀⠀⣿⣿⣿⣿⣿⣿⣿⠀⠀⠈⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣾⣿⣿⣿⣿⣷⣿⣿⣿⠁⠀⢸⣿⣿⣿⣿⣿⡏⠀⠀
⠀⠀⢿⣿⣿⣿⣿⣿⣿⠀⠀⠀⢻⣿⣿⣿⣿⣿⡇⠀⠀⠀⢸⣿⣿⣿⣿⣟⣿⣿⣿⣿⣿⣿⣿⣿⡏⠀⠀⢹⣿⣿⣿⣿⣿⠇⠀⠀
⠀⠀⠈⣿⣿⣿⣿⣿⣿⡄⠀⠀⢸⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡯⣿⣿⣿⣿⣧⣿⣿⠿⠇⠀⠀⢸⣿⣿⣿⣿⡿⠀⠀⠀
⠀⠀⠀⠘⣿⣿⣿⣿⣿⡆⠀⠀⠈⣿⣿⣿⣿⣿⠛⠛⠛⠛⢻⣿⣿⣿⣿⣷⣿⣿⣿⣿⣿⣿⠃⠀⠀⠀⠀⢸⣿⣿⣿⣿⠁⠀⠀⠀
⠀⠀⠀⠀⠘⣿⣿⣿⣿⡇⠀⠀⠀⢸⣿⣿⣿⣿⣤⣤⣤⣤⣤⣿⣿⣿⡿⣿⣿⣿⣿⣿⣿⡏⠀⠀⠀⠀⠀⢘⢿⣿⣿⠃⠀⠀⠀⠀
⠀⠀⠀⠀⠀⠈⢿⣿⣿⠧⢄⠀⠀⠘⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⢿⣿⣿⣿⣿⣿⣿⡇⠀⠀⠀⠀⠀⡎⣠⢹⠁⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⢹⠁⠀⣈⠣⡀⠀⠻⣿⣿⣿⠀⠀⠀⠀⠀⢸⣿⣿⠁⣿⣿⣿⣿⣿⡿⠀⠀⠀⠀⠀⠰⣷⡇⡇⠀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠸⡀⡄⡇⠑⠵⠄⠀⠀⠉⣿⣄⠀⠀⠀⢀⡸⠉⠉⣶⣿⣿⣿⣿⣿⠁⠀⠀⠀⠀⠀⠰⣿⢿⠁⠀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠀⠳⣧⢃⠀⠀⠀⠀⠀⠀⣿⣿⣿⣿⣿⣿⠀⠀⠀⣿⣿⣿⣿⣿⡿⠀⠀⠀⠀⠀⠀⠘⣿⠇⠀⠀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠀⠀⠻⡿⠄⠀⠀⠀⠀⠀⢸⣿⣿⣿⣿⣿⠀⠀⢀⣿⣿⣿⣿⣿⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⣿⣿⣿⣿⣿⠀⠀⢸⣿⣿⣿⣿⣿⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⣿⣿⣿⣿⡇⠀⠀⢸⣿⣿⣿⣿⡏⠀

All of my covariance matrices are going to be entirely built out of the data. For the bispectrum, the diagonal didn't agree too well with the analytic version, so I'll use the data driven diagonal. I will include a scalar modifier for the bispectrum covariance which I will say should be order 1. This will likely not make too large of an impact as it seems like the power spectrum is entirely driving the fits. For the bispectrum noise piece, I will be using the model power spectrum from wherever the model power spectrum is currently.⠀The parameters I will be fitting for are b1, b2, b3, and 3 nuisance noise parameters.⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
'''

import sys
sys.path.append('/home/kboone/software/Galaxy_Bias/Bispectrum/Convert_Bispectrum/')

import jax
import h5py
import optax
import numpy as np
import pandas as pd
import jax.numpy as jnp
from Fits_Helpers import *
from Visual_Helpers import *
from scipy.interpolate import CubicSpline as spline


jax.config.update("jax_enable_x64", True) 


z = 5
rescale = (8+1)/(z+1)


# All purpose parameters
L = 2000
V = L**3
N_grid = 256
N_tsc = 2048
kF = 2*np.pi/L
kN_tsc = N_tsc*np.pi/L
kN = N_grid*np.pi/L

phases = 25

noises = np.zeros(phases, dtype=np.float64)

for ph in np.arange(phases):
    pos_file = '../../Data/6E11_Gala_z5_Positions/Gala_ph0' + '{:02d}'.format(ph) + '.h5'
    
    with h5py.File(pos_file, 'r') as f_:
        dset = f_['dataset']
        pos = dset[:].T
        noises[ph] = L**3/len(pos)


def W(k):
    return (np.sin(np.pi*k/(2*kN_tsc)) / (np.pi*k/(2*kN_tsc)))**3


# Power spectrum data
kMax_P = kN

numBins = 10
kBins = np.geomspace(kF, kMax_P, numBins + 1)

P_bins = []
for ph in np.arange(phases):
    power_file = '/mnt/nvme1/kboone/Data/BigFiles/6E11_Gala_5/Gala_ph0' + '{:02d}'.format(ph) + '/Gala_256_ps.dat'
    P_bins_ind, kP, bin_idx, mask_P, N_P, N_P_tot = data_power(power_file, kBins, numBins)
    P_bins.append(P_bins_ind)

P_bins = np.array(P_bins)
std_P_bins = np.std(P_bins, axis=0, ddof=1)

C_P = np.cov(P_bins/std_P_bins, rowvar=False)
C_inv_P = np.linalg.inv(C_P) * (phases - numBins - 2) / (phases - 1)

Wk = W(kP)


# Power spectrum model
# The unbinned don't have Wk applied yet as it's applied later for the Bispectrum. The binned do have it applied.
b1b1_file = '/mnt/nvme1/kboone/Sims/PowerSpectra/b1b1_ps.dat'
b1b1_unbinned, b1b1 = sims_power(b1b1_file, kBins, numBins, Wk)
b1b1_unbinned *= rescale**2
b1b1 *= rescale**2

b2b2_file = '/mnt/nvme1/kboone/Sims/PowerSpectra/b2b2_ps.dat'
b2b2_unbinned, b2b2 = sims_power(b2b2_file, kBins, numBins, Wk)
b2b2_unbinned *= rescale**4
b2b2 *= rescale**4

b3b3_file = '/mnt/nvme1/kboone/Sims/PowerSpectra/b3b3_ps.dat'
b3b3_unbinned, b3b3 = sims_power(b3b3_file, kBins, numBins, Wk)
b3b3_unbinned *= rescale**6
b3b3 *= rescale**6

b2K2_file = '/mnt/nvme1/kboone/Sims/PowerSpectra/b2K2_ps.dat'
b2K2_unbinned, b2K2 = sims_power(b2K2_file, kBins, numBins, Wk, sym_factor=2)
b2K2_unbinned *= rescale**4
b2K2 *= rescale**4

b2F2_file = '/mnt/nvme1/kboone/Sims/PowerSpectra/b2F2_ps.dat'
b2F2_unbinned, b2F2 = sims_power(b2F2_file, kBins, numBins, Wk, sym_factor=2)
b2F2_unbinned *= rescale**4
b2F2 *= rescale**4

P1 = spline(kP, b1b1_unbinned, bc_type='natural')
P2 = spline(kP, b2b2_unbinned, bc_type='natural')
P3 = spline(kP, b3b3_unbinned, bc_type='natural')
PK = spline(kP, b2K2_unbinned, bc_type='natural')
PF = spline(kP, b2F2_unbinned, bc_type='natural')


# Bispectrum data
max_ksum = kN
min_ksum = max_ksum/4

min_k = 0.5*kF
max_k = 64.5*kF
Bs = []

for ph in np.arange(phases):
    bs_file = '/mnt/nvme1/kboone/Data/BigFiles/6E11_Gala_5/Gala_ph0' + '{:02d}'.format(ph) + '/Gala_256_comb.dat'
    B, kB = data_bispec(bs_file, min_k, max_k, min_ksum, max_ksum)
    Bs.append(B)

Bs = np.array(Bs)
# Whiten by dividing by standard deviations first.
std_B = np.std(Bs, axis=0, ddof=1)
C_B = np.cov(Bs/std_B, rowvar=False)
C_inv_B = np.diag(1/np.diag(C_B))

k1, k2, k3 = kB[:,0], kB[:,1], kB[:,2]

W1 = W(k1)
W2 = W(k2)
W3 = W(k3)

P1k1 = P1(k1)
P1k2 = P1(k2)
P1k3 = P1(k3)

P2k1 = P2(k1)
P2k2 = P2(k2)
P2k3 = P2(k3)

P3k1 = P3(k1)
P3k2 = P3(k2)
P3k3 = P3(k3)

PFk1 = PF(k1)
PFk2 = PF(k2)
PFk3 = PF(k3)

PKk1 = PK(k1)
PKk2 = PK(k2)
PKk3 = PK(k3)


# Bispectrum model
b1b1b2_file = '/mnt/nvme1/kboone/Sims/Bispectra/b1b1b2_comb.dat'
b1b1b2 = sims_bispec(b1b1b2_file, kB, sym_factor = 3) * W1*W2*W3 * rescale**4

b2b2b2_file = '/mnt/nvme1/kboone/Sims/Bispectra/b2b2b2_comb.dat'
b2b2b2 = sims_bispec(b2b2b2_file, kB, sym_factor = 1) * W1*W2*W3 * rescale**6

b1b2b3_file = '/mnt/nvme1/kboone/Sims/Bispectra/b1b2b3_comb.dat'
b1b2b3 = sims_bispec(b1b2b3_file, kB, sym_factor = 6) * W1*W2*W3 * rescale**6

b1b1K2_file = '/mnt/nvme1/kboone/Sims/Bispectra/b1b1K2_comb.dat'
b1b1K2 = sims_bispec(b1b1K2_file, kB, sym_factor = 3) * W1*W2*W3 * rescale**4

b1b1F2_file = '/mnt/nvme1/kboone/Sims/Bispectra/b1b1F2_comb.dat'
b1b1F2 = sims_bispec(b1b1F2_file, kB, sym_factor = 3) * W1*W2*W3 * rescale**4


# Fitting
def fit(ind):
    steps = 100_000_000
    lr = 1e-3
    store_every = 1000 # Only store 1 in this many indices, get convergence but without such a huge memory hit
    
    P_terms = np.array([b1b1,
                        b2b2, 
                        b3b3, 
                        b2K2,
                        b2F2,
                        np.bincount(bin_idx[mask_P], weights=(Wk**2*noises[ind]*N_P)[mask_P], minlength=numBins)/N_P_tot, 
                        -P_bins[ind]], dtype=np.float64)/std_P_bins
    
    P_chi2_matrix = jnp.asarray(P_terms @ C_inv_P @ P_terms.T, dtype=jnp.float64)

    B_terms = np.array([b1b1b2, 
                        b2b2b2, 
                        b1b2b3, 
                        b1b1K2,
                        b1b1F2,
                        -2*W1*W2*W3*noises[ind]**2*np.ones(len(b1b1b2), dtype=np.float64),
                        3*W1*W2*W3*noises[ind]**2*np.ones(len(b1b1b2), dtype=np.float64),
                        W1*W2*W3*noises[ind]*(P1k1+P1k2+P1k3),
                        W1*W2*W3*noises[ind]*(P2k1+P2k2+P2k3),
                        W1*W2*W3*noises[ind]*(P3k1+P3k2+P3k3),
                        W1*W2*W3*noises[ind]*(PKk1+PKk2+PKk3),
                        W1*W2*W3*noises[ind]*(PFk1+PFk2+PFk3),
                        -Bs[ind]], dtype=np.float64)/std_B
    B_chi2_matrix = jnp.asarray(B_terms @ C_inv_B @ B_terms.T, dtype=jnp.float64)
    
    def _chi_squared(params):
        b0, b00, b000, b1, b2, b3, bK2 = params
        bF2 = 1
        # b0, b1, b2, b3 = params
        P_bias_terms = jnp.array([b1**2,
                                  b2**2,
                                  b3**2,
                                  b2*bK2,
                                  b2*b1*bF2,
                                  b0,
                                  1.0], 
                                  dtype=jnp.float64)
        B_bias_terms = jnp.array([b1**2*b2,
                                  b2**3,
                                  b1*b2*b3,
                                  b1**2*bK2,
                                  b1**3*bF2,
                                  b00*b000,
                                  b0*b00,
                                  b00*b1**2,
                                  b00*b2**2,
                                  b00*b3**2,
                                  b00*b2*bK2,
                                  b00*b2*b1*bF2,
                                  1.0],
                                  dtype=jnp.float64)
        # return P_bias_terms @ P_chi2_matrix @ P_bias_terms
        # return B_bias_terms @ B_chi2_matrix @ B_bias_terms
        return (P_bias_terms @ P_chi2_matrix @ P_bias_terms) + 1.0*(B_bias_terms @ B_chi2_matrix @ B_bias_terms)
    
    chi_squared = jax.jit(_chi_squared)
    
    ind_initial_guess = jnp.array([1.0, 1.0, 1.0, 10.0, 40.0, 100.0, 1.0], dtype=jnp.float64)
    ind_init_chi2 = chi_squared(ind_initial_guess)
    
    def _scaled_chi2(params):
        return chi_squared(params*ind_initial_guess)/ind_init_chi2
    
    scaled_chi2 = jax.jit(_scaled_chi2)
    
    loss_and_grad = jax.value_and_grad(scaled_chi2)
    
    opt = optax.adam(lr)
    
    ind_params0 = jnp.ones(7, dtype=jnp.float64)
    opt_state0 = opt.init(ind_params0)
    loss0 = scaled_chi2(ind_params0) 
    
    def scan_step(carry, _):
        opt_state, params = carry
        loss, grads       = loss_and_grad(params)
        updates, opt_state = opt.update(grads, opt_state)
        params            = optax.apply_updates(params, updates)
        return (opt_state, params), (params, loss)        # record both
    
    # lax.scan returns stacked histories
    (_, _), (param_hist, loss_hist) = jax.lax.scan(
        scan_step, (opt_state0, ind_params0), None, length=steps
    )
    
    # prepend initial values so history length = num_steps+1
    ind_param_history = jnp.concatenate((ind_params0[None, :], param_hist), axis=0)  # (N+1, 5)
    loss_history = jnp.concatenate((loss0[None,], loss_hist), axis=0)  # (N+1,)
    
    best_idx = jnp.argmin(loss_history)
    ind_best_params = np.array(ind_param_history[best_idx])
    
    ind_param_history = np.array(ind_param_history)

    return ind_best_params, ind_param_history[::store_every]

    # np.save('Fits_z5/Both_Fit_History_'+str(ind)+'.npy', ind_param_history[::store_every])
    # np.save('Fits_z5/Both_Best_Fits_'+str(ind)+'.npy', ind_best_params)

    # return None


if __name__ == '__main__':
    best_params = []
    param_history = []
    inds = np.arange(phases)
    for ind in inds:
        best_params_ind, param_history_ind = fit(ind)
        best_params.append(best_params_ind)
        param_history.append(param_history_ind)
    np.save('Fits_z5/6E11_Best_Fits.npy', np.array(best_params))
    np.save('Fits_z5/6E11_Fit_History.npy', np.array(param_history))